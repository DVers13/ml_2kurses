{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b649983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/50   error=2.500000\n",
      "epoch 2/50   error=2.500000\n",
      "epoch 3/50   error=2.500000\n",
      "epoch 4/50   error=2.500000\n",
      "epoch 5/50   error=2.500000\n",
      "epoch 6/50   error=2.500000\n",
      "epoch 7/50   error=2.500000\n",
      "epoch 8/50   error=2.500000\n",
      "epoch 9/50   error=2.500000\n",
      "epoch 10/50   error=2.500000\n",
      "epoch 11/50   error=2.500000\n",
      "epoch 12/50   error=2.500000\n",
      "epoch 13/50   error=2.500000\n",
      "epoch 14/50   error=2.500000\n",
      "epoch 15/50   error=2.500000\n",
      "epoch 16/50   error=2.500000\n",
      "epoch 17/50   error=2.500000\n",
      "epoch 18/50   error=2.500000\n",
      "epoch 19/50   error=2.500000\n",
      "epoch 20/50   error=2.500000\n",
      "epoch 21/50   error=2.500000\n",
      "epoch 22/50   error=2.500000\n",
      "epoch 23/50   error=2.500000\n",
      "epoch 24/50   error=2.500000\n",
      "epoch 25/50   error=2.500000\n",
      "epoch 26/50   error=2.500000\n",
      "epoch 27/50   error=2.500000\n",
      "epoch 28/50   error=2.500000\n",
      "epoch 29/50   error=2.500000\n",
      "epoch 30/50   error=2.500000\n",
      "epoch 31/50   error=2.500000\n",
      "epoch 32/50   error=2.500000\n",
      "epoch 33/50   error=2.500000\n",
      "epoch 34/50   error=2.500000\n",
      "epoch 35/50   error=2.500000\n",
      "epoch 36/50   error=2.500000\n",
      "epoch 37/50   error=2.500000\n",
      "epoch 38/50   error=2.500000\n",
      "epoch 39/50   error=2.500000\n",
      "epoch 40/50   error=2.500000\n",
      "epoch 41/50   error=2.500000\n",
      "epoch 42/50   error=2.500000\n",
      "epoch 43/50   error=2.500000\n",
      "epoch 44/50   error=2.500000\n",
      "epoch 45/50   error=2.500000\n",
      "epoch 46/50   error=2.500000\n",
      "epoch 47/50   error=2.500000\n",
      "epoch 48/50   error=2.500000\n",
      "epoch 49/50   error=2.500000\n",
      "epoch 50/50   error=2.500000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from network import Network\n",
    "from fc_layer import FCLayer\n",
    "from conv_layer import ConvLayer\n",
    "from flatten_layer import FlattenLayer\n",
    "from activation_layer import ActivationLayer\n",
    "from activations import tanh, tanh_prime\n",
    "from losses import mse, mse_prime\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "IMG_WIDTH=200\n",
    "IMG_HEIGHT=200\n",
    "img_folder= \"D:/ML/data/data3\"\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "def create_dataset_PIL(img_folder):\n",
    "    \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "       \n",
    "            image_path= os.path.join(img_folder, dir1,  file)\n",
    "            image= np.array(Image.open(image_path))\n",
    "            image= np.resize(image,(IMG_HEIGHT,IMG_WIDTH,3))\n",
    "            image = image.astype('float32')\n",
    "            image /= 255  \n",
    "            img_data_array.append(image)\n",
    "            class_name.append(dir1)\n",
    "    return img_data_array , class_name  \n",
    "\n",
    "PIL_img_data, class_name=create_dataset_PIL(img_folder)\n",
    "target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
    "target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]\n",
    "\n",
    "net = Network()\n",
    "net.add(ConvLayer((200,200,3), (3,3), 1))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FlattenLayer())\n",
    "net.add(FCLayer(39204, 1))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(np.array(PIL_img_data[::1000]), tf.cast(list(map(int,target_val[::1000])),tf.int32), epochs=50, learning_rate=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eaf6fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.]])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(\n",
    "    \"D:/ML/data/data3/cats/4.jpg\", target_size=(200, 200)\n",
    ")\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = net.predict(img_array)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff9bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
